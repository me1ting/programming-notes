# 使用共享变量实现并发
## 使用监控goroutine避免使用共享变量

示例 [bank1](https://github.com/me1ting/gopl.io/blob/master/ch9/bank1/bank.go) 使用`监控goroutine`来避免使用共享变量，它的基本原理是：

- balance只能由监控goroutine进行读写，这样避免共享变量的同步问题
- 其它goroutine需要读取balance，通过通道读取
- 其它goroutine需要更新balance，通过更新通道递交

```go
var deposits = make(chan int) // 同步通道用于更新存款
var balances = make(chan int) // 同步通道用于接收余额

func Deposit(amount int) { deposits <- amount }
func Balance() int       { return <-balances }

func teller() {
	var balance int // balance is confined to teller goroutine
	for {
		select {
		case amount := <-deposits:
			balance += amount
		case balances <- balance:
		}
	}
}

// init函数，包初始化执行
func init() {
	go teller() // start the monitor goroutine
}
```

## 编写并发的非阻塞代码

示例 9.7 讲解如何编写一个支持并发访问的内存缓存，是用Go来编写并发代码的经典示例。

### memo4

```go
type entry struct {
	res   result
	ready chan struct{} // closed when res is ready
}

func New(f Func) *Memo {
	return &Memo{f: f, cache: make(map[string]*entry)}
}

type Memo struct {
	f     Func
	mu    sync.Mutex // guards cache
	cache map[string]*entry
}

func (memo *Memo) Get(key string) (value interface{}, err error) {
	memo.mu.Lock()
	e := memo.cache[key]
	if e == nil {
		// 第一次请求该key
		// 当前goroutine负责计算值，完成后广播给其它等待goroutine
		e = &entry{ready: make(chan struct{})}
		memo.cache[key] = e
		memo.mu.Unlock()
		e.res.value, e.res.err = memo.f(key)
		close(e.ready) // 广播值已准备
	} else {
		// 后续请求该key
		memo.mu.Unlock()
		<-e.ready // 会等待已准备
	}
	return e.res.value, e.res.err
}
```

这段代码有两个值得学习的点：

- 互斥量仅用于非阻塞代码：对cache的访问
- 使用一个`channel`来实现`CountDownLatch`的效果

### memo5

以上代码可以用`channel`来取代`Mutex`进行改写：

```go
// A request is a message requesting that the Func be applied to key.
type request struct {
	key      string
	response chan<- result // the client wants a single result
}
type Memo struct{ requests chan request }

// New returns a memoization of f. Clients must subsequently call Close.
func New(f Func) *Memo {
	memo := &Memo{requests: make(chan request)}
	go memo.server(f)
	return memo
}
func (memo *Memo) Get(key string) (interface{}, error) {
	response := make(chan result)
	memo.requests <- request{key, response}
	res := <-response
	return res.value, res.err
}
func (memo *Memo) Close() { close(memo.requests) }

func (memo *Memo) server(f Func) {
	cache := make(map[string]*entry)
	for req := range memo.requests {
		e := cache[req.key]
		if e == nil {
			// This is the first request for this key.
			e = &entry{ready: make(chan struct{})}
			cache[req.key] = e
			go e.call(f, req.key) // call f(key)
		}
		go e.deliver(req.response)
	}
}
func (e *entry) call(f Func, key string) {
	// Evaluate the function.
	e.res.value, e.res.err = f(key)
	// Broadcast the ready condition.
	close(e.ready)
}
func (e *entry) deliver(response chan<- result) {
	// Wait for the ready condition.
	<-e.ready
	// Send the result to the client.
	response <- e.res
}
```

其值得学习的点包括：

- 使用一个`channel+goroutine`接收和处理`Get`请求
- 请求封装了真正的`Request`和`Response`对象
- `Response`对象封装了Channel来返回结果
- 处理`Request`的goroutine使用了两个额外的`goroutine`来计算值与响应值

## 库

### sync.Mutex

`互斥量`实现，值得注意的是：

- 互斥量是**不可重入**的
- 解锁操作不绑定goroutine

#### 使用技巧

习惯上使用defer来释放互斥量：

```
m.Lock()
defer m.UnLock()
```

#### 重复加锁的解决方案

书中给出的方案是避免重复加锁，要求子过程不可导出，并内部约定调用它的前提是已经获取锁。

### sync.RWMutex

读写锁分离的互斥量实现。

### sync.Once

保证在竞争情况下只执行一次的执行器，常用于延迟初始化的情况。