# Stream API

[流处理](https://en.wikipedia.org/wiki/Stream_processing)是编程的一种范式，将数据流作为计算的输入输出目标。

`Stream API`是Java基于流处理的思想，为处理集合数据提供的一套`map-reduce`风格的函数式API，在其它支持函数式编程的语言中也有类似风格的API。

## 工作模式

Stream的工作模式是：

1. **创建**一个Stream
2. 在一到多个步骤中，将初始Stream **转换** 为另一个Stream的中间操作
3. 使用**终止**操作产生结果，会强制其之前的延迟操作立即执行

## 创建流

略

## 转换流

### filter、map和flatMap

`filte`用于将stream中的元素进行过滤，返回新的stream。

`map`用于对stream中的元素进行转换，返回新的stream。

`flatMap`将元素为流的流中的子流展开。

### 提取子流

`limit(n)`返回流的前n个元素的新流。

`skip(n)`跳过流的前n个元素的新流。

`Stream.concat()`将两个流连接起来，返回新流。

`peek()`返回与原始流相同元素的流，但每次获取元素时，会调用一个函数。

### 有状态的转换

`无状态`指从一个filter或map得到的流中获取某个元素时，结果不依赖之前的元素。而以下方法得到的流需要依赖之前的元素：

`distinct()`方法返回一个具有相同顺序、去除重复的流。

`sorted()`返回一个排序了的流。

## 终止操作

### 简单的聚合方法/终止操作

聚合方法都是**终止操作**，它们会返回一个`Optional`值表示运算结果。

`count()`返回元素的个数

`max()`和`min()`返回流中元素的最值

`findFirst()`返回非空集合的第一个元素

`findAny()`返回任意一个匹配的元素

`anyMatch()`返回是否存在任意一个匹配

`allMatch()`返回是否所有匹配

`noneMatch()`返回是否所有不匹配

还包括这些终止操作：

`iterator()`可以返回一个迭代器，用于访问元素。

`toArray()`可以获得包含所有元素的数组

`forEach()` 内部迭代，与元素在流中顺序无关

`forEachOrdered()`内部迭代，按元素在流中顺序

### Optional类型

Optional是一种null safe的值封装。

### 聚合

`reduce()`方法有三种重载形式：

```
Optional<T>	reduce(BinaryOperator<T> accumulator)
T	reduce(T identity, BinaryOperator<T> accumulator)
U	reduce(U identity, BiFunction<U,T,U> accumulator, BinaryOperator<U> combiner)
```

首先看第一种，如对一个元素为Integer的Stream进行求和运算：

```
Stream<Integer> values = ...
Optional<Integer> sum = values.reduce(Integer::sum);
```

聚合方法有一个聚合操作op，聚合结果是$v_1 op v_2 op v_3...$的值。聚合操作必须是联合的，也就是与运算顺序无关，满足交换律和结合律。

第二种要求提供一个计算的起点。一般而言，存在$eopv=v$，e就可以当作起点。如果希望空返回值为0，上述求和运算可以修改为：

```
Integer sum = values.reduce(0,Integer::sum);
```

第三种参数分别为起点值、聚合器、合并器。如对元素为String的Strem进行字符串长度求和运算：

```
Integer sum = strs.reduce(0,
    (total,world)->total+word.length(),
    (total1,total2)->total1+total2);
```

### 收集

可能希望收集元素到容器中，如HashSet。因为并行的关系，需要考虑线程安全，不能手动直接放入一个HashSet。而应当使用collect()方法

```
R	collect(Supplier<R> supplier, BiConsumer<R,T> accumulator, BiConsumer<R,R> combiner)
R	collect(Collector<T,A,R> collector)
```

第一种接口接受三个参数：

- 创建目标实例的方法
- 添加到目标中的方法
- 合并两个目标类型的方法

以HashSet为例：

```
HashSet<String> result=stream.collect(HashSet::new,HashSet::add,HashSet::addAll);
```

`Collector`接口可以看作是对第一种接口的参数的封装。使用Collector封装的好处在于，可以提供一些常见容器的基本实现，Collectors就是这样一个工具类。使用Collectors的以上代码改进：

```
HashSet<String> result=stream.collect(Collectors.toSet());
```

Collectors还提供了许多实用的Collector实现：

- `toCollection()`` 可以自定义Collection实例
- `joining()`` 连接字符串
- `summmarizing(Int|Long|Double)` 聚合求总和、平均值、最大值、最小值。

当收集到map中时，需要我们指定如何产生key与value。如:

```
Map<Integer,String> idToName=people.collect(Collectors.toMap(Person::getId,Person::getName));
```

#### 分组和分片

分组是指grouping，分片是指partition。

使用Collectors.groupingBy()方法返回的收集器，可以将元素进行分组处理，返回Map类型的结果。如：

```
Map<String,List<Locale>> countryToLocales=locales.collect(
    Collectors.groupingBy(Locale::getCountry));
```

其中`Locale::getCountry`就是**分类函数**，当分类函数为predicate函数(断言，返回boolean)时，使用partitioningBy()效率更高。

groupingBy会产生值为列表的Map对象。可以对分组后的列表进行处理，需要提供"downstream 收集器"。如将List替换为Set:

```
Map<String,List<Locale>> countryToLocales=locales.collect(
    Collectors.groupingBy(Locale::getCountry),toSet());
```

## 原始类型流

将原始类型数据进行包装再转换为流是很低效的，因此提供了`IntStream`,`LongStream`,`DoubleStream`。

## 并行流

默认创建的流是串行的，可以通过`parallelStream()`创建并行流，或parallel()方法将串行流转换为并行流。需要确保传给并行流的函数都是线程安全的。
